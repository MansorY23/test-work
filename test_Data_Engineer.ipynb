{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "##Тестовое задание на позицию Data Engineer.\n",
    "\n",
    "Задание включает в себя 3 небольших задачи. В каждой задаче **рекомендуется** оставлять комментарии, код должен быть оформлен согласно **PEP8**. Задания необходимо выполнить без использования Pandas и готовых библиотек для API Яндекс.Погоды.\n",
    "\n",
    "**Перед выполнением тестового задания, необходимо скопировать notebook к себе на диск, и выполнять тестовое в своей копии**."
   ],
   "metadata": {
    "id": "3ffM1IGEysic"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "####1. Выгрузка данных из API Яндекс.Погоды и преобразование их в csv\n",
    "\n",
    "Используя API Яндекс.Погоды, необходимо выгрузить прогнозные данные за 7 дней для Москвы, Казани, Санкт-Петербурга, Тулы и Новосибирска. В случае, если API отдает пустые значения за день, то их необходимо удалить.\n",
    "\n",
    "Информация должна быть представлена по часам с расширенным набором полей по осадкам.\n",
    "\n",
    "Полученный json необходимо преобразовать в csv, формат:\n",
    "\n",
    "\\begin{array}{ccc}\n",
    "\\text{city}, \\text{date}, \\text{hour}, \\text{temperature_c}, \\text{pressure_mm}, \\text{is_rainy} \\\\\n",
    "Moscow, 19.08.2023, 12, 27, 750, 0 \\\\\n",
    "Moscow, 19.08.2023, 13, 27, 750, 0 \\\\\n",
    "... \\\\\n",
    "Kazan, 19.08.2023, 12, 20, 770, 1 \\\\\n",
    "Kazan, 19.08.2023, 13, 21, 770, 0 \\\\\n",
    "\\end{array}\n",
    "\n",
    "**Описание полей:**\n",
    "\n",
    "city - Город\n",
    "\n",
    "date - Дата события\n",
    "\n",
    "hour - Часы\n",
    "\n",
    "temperature_c - Температура в Цельсиях\n",
    "\n",
    "pressure_mm - Давление в мм ртутного столба\n",
    "\n",
    "is_rainy - Флаг наличия дождя в конкретный день и час (см. документацию по API - описание полей).\n",
    "\n",
    "Полученный csv необходимо выгрузить на облачный диск и в конце решения предоставить ссылку.\n",
    "\n",
    "**Ссылка на получение ключа:** https://yandex.ru/dev/weather/doc/dg/concepts/about.html#about__onboarding\n",
    "\n",
    "\n",
    "**Дополнительно ответьте на вопросы:** какие существуют возможные пути ускорения получения данных по API и их преобразования? Возможно ли эти способы использовать в Airflow?"
   ],
   "metadata": {
    "id": "-bzGaxhZy3pd"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rcKOBi7P1YHG",
    "outputId": "4220490f-e25b-4383-aab8-392a59065074"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import requests\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass\n",
    "import csv\n",
    "from typing import Optional\n",
    "\n",
    "access_key: str = '5f76604b-8180-4b9f-8d99-bca210a4fbae'\n",
    "api_url: str = 'https://api.weather.yandex.ru/v2'\n",
    "path: str = 'weekly_forecast.csv'\n",
    "\n",
    "def get_city_coords(city_name: str,\n",
    "                    country_name: str = 'Russia'):\n",
    "  response = requests.get('https://api.api-ninjas.com/v1/geocoding',\n",
    "                         params={'city': city_name,\n",
    "                                 'country': country_name})\n",
    "  if response.status_code == 200:\n",
    "      return response.json()\n",
    "\n",
    "  else:\n",
    "    return None\n",
    "\n",
    "cities_geodata: dict = {\n",
    "    'Moscow': {\n",
    "        'name': 'Moscow',\n",
    "        'latitude': 55.75222,\n",
    "        'longitude': 37.61556},\n",
    "    'Kazan': {\n",
    "      'name': 'Kazan',\n",
    "      'latitude': '55.78874',\n",
    "      'longitude': '49.12214'\n",
    "          },\n",
    "    'Petersburg': {\n",
    "      'name': 'Petersburg',\n",
    "      'latitude': '59.937500',\n",
    "      'longitude': '30.308611'\n",
    "    },\n",
    "    'Tula': {\n",
    "      'name': 'Tula',\n",
    "      'latitude': '54.204838',\n",
    "      'longitude': '37.618492'\n",
    "    },\n",
    "    'Novosibirsk': {\n",
    "      'name': 'Novosibirsk',\n",
    "      'latitude': '55.018803',\n",
    "      'longitude': '82.933952'\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def get_weather_data(api_url: str, headers: dict,\n",
    "                     params: dict) -> Optional[dict]:\n",
    "\n",
    "  response = requests.get(f\"{api_url}/forecast\",\n",
    "                        headers=headers,\n",
    "                        params=params\n",
    "                          )\n",
    "  if response.status_code == 200:\n",
    "      return response.json()\n",
    "\n",
    "  else:\n",
    "    return None\n",
    "\n",
    "\n",
    "def is_rainy(condition: str) -> int:\n",
    "  if 'rain' in condition:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "\n",
    "def format_date(date: str):\n",
    "  date = datetime.strptime(date, '%Y-%m-%d')\n",
    "  formatted_date = date.strftime('%d.%m.%Y')\n",
    "  return formatted_date\n",
    "\n",
    "def get_hourly_city_forecast(api_url: str,\n",
    "                             api_key: str,\n",
    "                             city_info: dict) -> list:\n",
    "  processed_data: list = []\n",
    "\n",
    "  params = {'lat': city_info.get('latitude', None),\n",
    "            'lon': city_info.get('longitude', None),\n",
    "            'limit':7, 'extra': True, 'hours': True}\n",
    "  headers = {\n",
    "    'X-Yandex-Weather-Key': api_key\n",
    "  }\n",
    "\n",
    "  forecast_data: dict = get_weather_data(api_url=api_url,\n",
    "                                         params=params, headers=headers)\n",
    "\n",
    "  for day in forecast_data.get('forecasts'):\n",
    "    if not day.get('hours'):\n",
    "      pass\n",
    "    for hour in day.get('hours'):\n",
    "      necessary_data: dict = {'name': city_info.get('name'),\n",
    "                              'date': format_date(day.get('date')),\n",
    "                              'hour': hour.get('hour'), 'temp': hour.get('temp'),\n",
    "                              'pressure_mm': hour.get('pressure_mm'),\n",
    "                              'is_rainy': is_rainy(hour.get('condition'))}\n",
    "      processed_data.append(necessary_data)\n",
    "\n",
    "  return processed_data\n",
    "\n",
    "\n",
    "def save_forecasts(path: str, data: list) -> bool:\n",
    "    field_names = data[0].keys()\n",
    "    print(field_names)\n",
    "    print(type(field_names))\n",
    "    try:\n",
    "      with open(path, 'w') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=field_names)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)\n",
    "    except Exception as e:\n",
    "      print(e)\n",
    "      return False\n",
    "    else:\n",
    "      return True\n",
    "\n",
    "def get_cities_forecast(api_url: str,\n",
    "                        api_key: str,\n",
    "                        cities: dict):\n",
    "  all_cities_forecasts: list = []\n",
    "\n",
    "  for city in cities.values():\n",
    "    city_forecast: list = get_hourly_city_forecast(api_url=api_url,\n",
    "                                                   api_key=api_key,\n",
    "                                                   city_info=city)g\n",
    "    all_cities_forecasts.extend(city_forecast)\n",
    "  return all_cities_forecasts\n",
    "\n",
    "\"\"\"\n",
    "дополнительные вопросы:\n",
    "  можно сделать код асинхронным, например через aiohttp а запросы обрабатывать в разных процессах\n",
    "\"\"\""
   ],
   "metadata": {
    "id": "TAK327i-yuYw"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def main(csv_path: str):\n",
    "  forecasts = get_cities_forecast(api_url=api_url, api_key=access_key,\n",
    "                             cities=cities_geodata)\n",
    "  save_forecasts(path='/content/drive/MyDrive/weekly_forecast.csv', data=forecasts)\n",
    "main(path)\n",
    "\n",
    "# csv here: https://drive.google.com/file/d/1dT781F0Yg0WRP2G7Hh5lnMSU3nQdrz7L/view?usp=sharing"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lyKNzPVWA53c",
    "outputId": "612f7f88-0da2-4557-b4aa-2b221e05549b"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dict_keys(['name', 'date', 'hour', 'temp', 'pressure_mm', 'is_rainy'])\n",
      "<class 'dict_keys'>\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "O-nXVhaBqU9k"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "####2. Загрузка данных в БД (PostgreSQL).\n",
    "\n",
    "Используя полученный csv файл, необходимо загрузить данных в PostgreSQL. Предварительно в БД необходимо создать схемы: для приемки сырых данных и для будущих агрегирующих таблиц.\n",
    "\n",
    "При создании таблиц приветствуется использование партицирования и индексирования (по возможности и необходимости).\n",
    "\n",
    "В решении необходимо показать код загрузки данных, скрипты создания схем и таблиц для пункта 2 и 2.1.\n",
    "\n",
    "Подсказка: для решения задачи нужно развернуть БД, мы рекомендуем это сделать локально с помощью докера."
   ],
   "metadata": {
    "id": "HOAEAH0kzCAk"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import psycopg2\n",
    "csv_load_path = '/content/drive/MyDrive/weekly_forecast.csv'\n",
    "csv_load_query: str = \"COPY forecast_raw.forecasts_hourly_raw FROM STDIN DELIMITER ',' CSV HEADER\"\n",
    "\n",
    "def load_csv( sql_query: str, file_path: str):\n",
    "  conn = psycopg2.connect(host='cornelius.db.elephantsql.com',\n",
    "                      port='5432', dbname='fzpvuodf', user='fzpvuodf',\n",
    "                          password='l5njBN5YHeq8lK93Xb1oRl7YgSAnjDM-')\n",
    "\n",
    "  cur = conn.cursor()\n",
    "  with open(path, 'r') as file:\n",
    "    cur.copy_expert(sql_query, file)\n",
    "\n",
    "  conn.commit()\n",
    "  conn.close()\n",
    "\n",
    "load_csv(path=csv_load_path, sql_query=csv_load_query)"
   ],
   "metadata": {
    "id": "Isa3SMnxyudM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "DROP SCHEMA IF EXISTS forecast_raw;\n",
    "DROP SCHEMA IF EXISTS forecast_agg;\n",
    "\n",
    "CREATE SCHEMA IF NOT EXISTS forecast_raw;\n",
    "CREATE SCHEMA IF NOT EXISTS forecast_agg;\n",
    "\n",
    "DROP TABLE IF EXISTS forecast_raw.forecasts_hourly_raw;\n",
    "CREATE TABLE IF NOT EXISTS forecast_raw.forecasts_hourly_raw (\n",
    "\tcity TEXT,\n",
    "\tforecast_date TEXT,\n",
    "\tforecast_hour SMALLINT,\n",
    "\ttemperature_c SMALLINT,\n",
    "\tpressure_mm SMALLINT,\n",
    "\tis_rainy Boolean\n",
    ")\n",
    "\n",
    "\"\"\""
   ],
   "metadata": {
    "id": "WNgIY_wr7JGH"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "####2.1 Формирование витрин (PostgreSQL).\n",
    "\n",
    "1. Используя таблицу с сырыми данными, необходимо собрать витрину, где для каждого города и дня будут указаны часы начала дождя. Условимся, что дождь может начаться только 1 раз за день в любом из городов.\n",
    "\n",
    "2. Необходимо создать витрину, где для каждого города, дня и часа будет рассчитано скользящее среднее по температуре и по давлению.\n",
    "\n",
    "\n",
    "Полученные запросы необходимо вставить в google colab, а результаты - выгрузить в формате csv/xlsx и выложить в виде ссылки в google colab.\n",
    "\n",
    "Подсказка: если в исходном файле не было факта начала дождя, то необходимо расставить рандомно значения факта дождя в таблице с сырыми данными.\n"
   ],
   "metadata": {
    "id": "kcubMA6zqy5l"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "CREATE TABLE forecast_agg.rain_start_hour AS\n",
    "SELECT city, forecast_date, MIN(forecast_hour) AS rain_start\n",
    "FROM forecast_raw.forecasts_hourly_raw\n",
    "WHERE is_rainy = TRUE\n",
    "GROUP BY city, forecast_date\n",
    "ORDER BY city, forecast_date;\n",
    "\n",
    "CREATE TABLE forecast_agg.moving_avg_temp_and_pressure AS\n",
    "SELECT city, forecast_date, forecast_hour, temperature_c,\n",
    "AVG(temperature_c) OVER (PARTITION BY city, forecast_date ORDER BY forecast_hour\n",
    "\t\t\t\t\t\t\t\tROWS BETWEEN 23 PRECEDING AND CURRENT ROW) AS moving_avg_temp,\n",
    "AVG(pressure_mm) OVER (PARTITION BY city, forecast_date ORDER BY forecast_hour\n",
    "\t\t\t\t\t\t\t\tROWS BETWEEN 23 PRECEDING AND CURRENT ROW) AS moving_avg_pressure\n",
    "FROM forecast_raw.forecasts_hourly_raw\n",
    "ORDER BY city, forecast_date, forecast_hour;\n",
    "\"\"\"\n",
    "import psycopg2\n",
    "def download_csv(sql_query: str, file_path: str):\n",
    "  conn = psycopg2.connect(host='cornelius.db.elephantsql.com',\n",
    "                      port='5432', dbname='fzpvuodf', user='fzpvuodf',\n",
    "                          password='l5njBN5YHeq8lK93Xb1oRl7YgSAnjDM-')\n",
    "\n",
    "  cur = conn.cursor()\n",
    "  with open(file_path, 'w') as file:\n",
    "    cur.copy_expert(sql_query, file)\n",
    "\n",
    "  conn.commit()\n",
    "  conn.close()\n",
    "\n",
    "download_csv(sql_query='copy (select * from forecast_agg.rain_start_hour ) TO STDOUT WITH CSV HEADER',\n",
    "             file_path='/content/drive/MyDrive/rain_start_hour.csv')\n",
    "download_csv(sql_query='copy (select * from forecast_agg.moving_avg_temp_and_pressure ) TO STDOUT WITH CSV HEADER',\n",
    "             file_path='/content/drive/MyDrive/moving_avg_temp_and_pressure.csv')\n",
    "\n",
    "# result rain start hour: https://drive.google.com/file/d/1jgdb-BH4rAb27IKxRbLimhStK3kFMtOQ/view?usp=sharing\n",
    "# result moving_avg_temo_and_pressure https://drive.google.com/file/d/1jgdb-BH4rAb27IKxRbLimhStK3kFMtOQ/view?usp=sharing"
   ],
   "metadata": {
    "id": "TopO7d8GvR6x"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
